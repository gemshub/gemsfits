+ completed or partially completed
- to be completed

+ describe/document command line parameters to start gemsfit2 and csvtoejdb utility program
+ check if GEMSFIT input file exists by writing a new template input file (to prevent overwrite)
+ documentation in the GEMSFIT template input file (fitting bulk composition with L linked parameters) 
+ write all possible option the user has for data to compare
- see more possible errors and add them to the gemfit_error function.

+ Printing class - printing in /results/FIT_results.csv
- test inverse weighting more
- add normalized target function (by average from experimental data)
+ solid-solution composition as element bulk phase concentration
- test solid-solution with solchas
+ test the reaction constraint 
- also test if logk is respected at higher temperatures
- test interaction parameters

- problems with GEMS convergence - can affect the convergence as BOBYQA - decides how to change parameters based on first residuals

- type of data to compare (molality and log molality) etc...
- add density for data to compare.
+ add DMc, fDQF parameters
+ check Tk and P - if implemented
- make test for Linked parameters - simple pH titration system
- make test of geobarometry with qtz rutile paper.
+ added phase amount, phase vlolume, dcomp amount, dcomp activity coeficient
- not added Eh, osmotic coeficient.
- think about units, how to make a uniform strategy for units.

+ add bulk composition as parameters 
+ work on L (linked) type parameters  

+ look over the statistics !! think about the weighting matrix problem in the Var/Cov calculation.


+ make a separate RUN function in TGfittask so one can access the data manager and calculate statistics before the fitting procedure.
- make statistics for the reaction dependent parameters as the statistics are fit independent - just add the parameters into the statistics parameter vector.


EJDB database maintenance functionality:
- try installing ejdb console via nodejs (as given on ejdb.org)
- the sense of 'collection': as a modeling application project name? as experimental dataset? any other semantics? 
- backup to JSON text file (the whole DB, one exp.dataset, etc.)
- restore from JSON text file
- updating/owerwriting documents e.g. for error corrections in experimental data, adding new information for experimental samples. 
- what if one wants to sellect data form more collections
